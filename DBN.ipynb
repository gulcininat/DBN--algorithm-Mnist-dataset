{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DBN_csv.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMGhY/jYXMq2HFgotwzaoqR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":129},"id":"cgUEsz1XYAhb","executionInfo":{"status":"error","timestamp":1622987510111,"user_tz":-180,"elapsed":1649,"user":{"displayName":"GÜLÇİN İNAT","photoUrl":"","userId":"13817032197419416640"}},"outputId":"89a13538-5935-46c9-9601-ee19a195c3c9"},"source":["#    pip install git+git://github.com/albertbup/deep-belief-network.git  #CPU\n","#    pip install git+git://github.com/albertbup/deep-belief-network.git@master_gpu   #GPU\n","\n","\n","\n","# bu kütüphaneler python temel kütüphanesinde yok. bu yüzden biz eklememiz lazım.\n","# kodlar python 2 verison ile uyumlu. 3 ile çalışmayan fonk ları var. \n","#   fakat bu kodda optimizasyonu yapıldı. python 3 de de aşağıdaki kodlar çalışabilmekte. \n","\n","#git+git yazılması da:  .git uzantılı dosyayı yani githubtadakileri rahatlıkla indirebilimeyi sağlar."],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-838e91fb7794>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install git+git://github.com/albertbup/deep-belief-network.git  #CPU\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cjRm0FWBcDbD","executionInfo":{"status":"ok","timestamp":1623001307427,"user_tz":-180,"elapsed":24351,"user":{"displayName":"GÜLÇİN İNAT","photoUrl":"","userId":"13817032197419416640"}},"outputId":"a640cfcc-9621-4753-912d-9093e5581427"},"source":["#Google Drive Baglantisi\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd gdrive/My Drive/Derin Öğrenme/DBN/\n","%ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/Derin Öğrenme Final/DBN\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PzgcFZRrcD2R","executionInfo":{"status":"ok","timestamp":1623001321373,"user_tz":-180,"elapsed":5553,"user":{"displayName":"GÜLÇİN İNAT","photoUrl":"","userId":"13817032197419416640"}},"outputId":"598cccdf-719c-45c0-8b59-095d9a4e08ce"},"source":["# Import NumPy\n","import numpy as np\n","np.random.seed(42)  # Random besleme sabitledik. rastsallık için belli bir uzay seçimi. YANİ WEİGTHLERİMİZİN DAHA İYİ ÇIKMASINI SAĞLAR !!\n","\n","# Import scikit-learn DBN modulleri\n","#Veriseti olarak MNIST database kullanildi  - mnist veriseti: karakter yazılımıdır. 0-9a kadar sayıları farklı elyazısı ile. 28*28 lik görüntü.\n","from sklearn.datasets import load_digits                # dataset yüklendi\n","from sklearn.model_selection import train_test_split    # train ve testi split etsin yani ayırsın bu fonk. ile\n","from sklearn.metrics.classification import accuracy_score  # acc öğrenmek için\n","\n","\n","# Import deep-belief network\n","# at https://github.com/albertbup/deep-belief-network\n","from dbn.tensorflow import SupervisedDBNClassification\n","# Graphs\n","import matplotlib.pyplot as plt   # grafik için"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"5Zppsdz-cD4Z"},"source":["# MNIST dataseti Yukle\n","from sklearn.datasets import fetch_openml\n","mnist = fetch_openml(\"mnist_784\")\n","\n","#el yazı tanıma çalışması. -28*28 croplayıp veriyor. "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VSvC8ImcD6l"},"source":["# Sinif vektorleri olusturalim (MNIST) \n","class_count = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  #10 sınıf var yani 0-9 arası rakamlar\n","X = []  #datalar\n","Y = []  # etiketler \n","\n","# HEr classdan 100 ornek al\n","for i in range(0, len(mnist.data)):\n","    target_value = int(mnist.target[i])  #sınıfları atadık\n","    if class_count[target_value] < 100:\n","        X.append(mnist.data[i])          #dataları atadık\n","        Y.append(target_value)\n","        class_count[target_value] += 1\n","    if sum(class_count) == 1000:\n","        break\n","\n","# NumPy donusumu çünkü hızlı işlem yapar normal matristen ziyade.\n","X = np.array(X)\n","Y = np.array(Y)\n","\n","# Pixel degerlerini normalize ediyor (MNIST)   \n","X = (X / 256).astype(np.float32) #  0-255 arası pixel değerlerini 0-1 arasına sabitler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G1yNbMn-cD8_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623001427332,"user_tz":-180,"elapsed":246,"user":{"displayName":"GÜLÇİN İNAT","photoUrl":"","userId":"13817032197419416640"}},"outputId":"f16becc3-2de4-470c-8b1f-a824e5ddade5"},"source":["print(X.shape)\n","print(Y)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1000, 784)\n","[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7 3 8 6 9 0 5 6\n"," 0 7 6 1 8 7 9 3 9 8 5 9 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 4 5 6 1 0 0 1 7 1 6\n"," 3 0 2 1 1 7 9 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1 5 7 1 7 1 1 6 3 0 2 9\n"," 3 1 1 0 4 9 2 0 0 2 0 2 7 1 8 6 4 1 6 3 4 5 9 1 3 3 8 5 4 7 7 4 2 8 5 8 6\n"," 7 3 4 6 1 9 9 6 0 3 7 2 8 2 9 4 4 6 4 9 7 0 9 2 9 5 1 5 9 1 2 3 2 3 5 9 1\n"," 7 6 2 8 2 2 5 0 7 4 9 7 8 3 2 1 1 8 3 6 1 0 3 1 0 0 1 7 2 7 3 0 4 6 5 2 6\n"," 4 7 1 8 9 9 3 0 7 1 0 2 0 3 5 4 6 5 8 6 3 7 5 8 0 9 1 0 3 1 2 2 3 3 6 4 7\n"," 5 0 6 2 7 9 8 5 9 2 1 1 4 4 5 6 4 1 2 5 3 9 3 9 0 5 9 6 5 7 4 1 3 4 0 4 8\n"," 0 4 3 6 8 7 6 0 9 7 5 7 2 1 1 6 8 9 4 1 5 2 2 9 0 3 9 6 7 2 0 3 5 4 3 6 5\n"," 8 9 5 4 7 4 2 7 3 4 8 9 1 9 2 8 7 9 1 8 7 4 1 3 1 1 0 2 3 9 4 9 2 1 6 8 4\n"," 7 7 4 4 9 2 5 7 2 4 4 2 1 9 7 2 8 7 6 9 2 2 3 8 1 6 5 1 1 0 2 6 4 5 8 3 1\n"," 5 1 9 2 7 4 4 4 8 1 5 8 9 5 6 7 9 9 3 7 0 9 0 6 6 2 3 9 0 7 5 4 8 0 9 4 1\n"," 2 8 7 1 2 6 1 0 3 0 1 1 8 2 0 3 9 4 0 5 0 6 1 7 7 8 1 9 2 0 5 1 2 2 7 3 5\n"," 4 9 7 1 8 3 9 6 0 3 1 1 2 6 3 5 7 6 8 3 9 5 8 5 7 6 1 1 3 1 7 5 5 5 2 5 8\n"," 7 0 9 7 7 5 0 9 0 0 8 9 2 4 8 1 6 1 6 5 1 8 3 4 0 5 5 8 3 6 2 3 9 2 1 1 5\n"," 2 1 3 2 8 7 3 7 2 4 6 9 7 2 4 2 8 1 1 3 8 4 0 6 5 9 3 0 9 2 4 7 1 2 9 4 2\n"," 6 1 8 9 0 6 6 7 9 9 8 0 1 4 4 6 7 1 5 7 0 3 5 8 4 7 1 2 5 9 5 6 7 5 9 8 8\n"," 3 6 9 7 0 7 5 7 1 1 0 7 9 2 3 7 3 2 4 1 6 2 7 5 5 7 4 0 2 6 3 6 4 0 4 2 6\n"," 0 0 0 0 3 1 6 2 2 3 1 4 1 5 4 6 4 7 2 8 7 9 2 0 5 1 4 2 8 3 2 4 1 5 4 6 0\n"," 7 9 8 4 9 8 0 1 1 0 2 2 3 2 4 4 5 8 6 5 7 7 8 8 9 7 4 7 3 2 0 8 6 8 6 1 6\n"," 8 9 4 0 9 0 4 1 5 4 7 5 3 7 4 9 8 5 8 6 3 8 6 9 9 1 8 3 5 8 6 5 9 7 2 5 0\n"," 8 5 1 1 0 9 1 8 6 7 0 9 3 0 8 8 9 6 7 8 4 7 5 9 2 6 7 4 5 9 2 3 1 6 3 9 2\n"," 2 5 6 8 0 7 7 1 9 8 7 0 9 9 4 6 2 8 5 4 5 5 7 3 6 4 3 2 5 6 4 4 0 4 4 6 7\n"," 2 4 3 3 8 0 0 3 2 2 9 8 2 3 7 0 0 2 3 3 8 4 3 5 7 6 4 7 7 8 5 9 7 0 3 6 2\n"," 4 3 4 4 7 5 9 6 9 0 7 4 2 7 3 6 5 8 4 5 5 2 5 6 8 5 8 4 0 9 9 2 9 8 4 2 6\n"," 9 0 6 4 2 5 0 0 3 6 5 0 6 5 8 5 0 3 5 8 6 9 3 8 6 0 9 3 0 5 6 2 3 6 0 3 6\n"," 0 3 8 2 8 0 8 0 6 3 5 8 8 5 3 5 6 8 3 8 5 8 8 8 3 6 5 3 8 5 5 6 6 3 6 8 5\n"," 8]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZB5USnfecJOD"},"source":["def deep_belief_net(hidden_layers_structure=[256, 256],         # rbm in kaç katmanlı olcağı, burada 2 katmanlı.\n","                    learning_rate_rbm=0.05,   # hem rbm için öğrenme oranı \n","                    learning_rate=0.1,        # hem de supervised yöntem için öğrenme oranı lazım.\n","                    n_epochs_rbm=10,          # rbm için de epoch değeri lazım. tek bir örnek için kaç defa tekrar edicek?\n","                    n_iter_backprop=100,      # buradaki epoch sayısı \n","                    batch_size=32,            # elimizdeki verisetinden kaçar kaçar alıcaz? tam bölünmeli hem traine hem  test e.\n","                    activation_function='relu', #DEĞİŞTİREBİLİRSİN !!!  # RBM in activasyon fonk yoktur. bu MLP nin yani supervised tarafının act fonk.udur.\n","                    dropout_p=0.2):           # RASTGELE, BAZI NÖRONLARI AKTİF BAZILARINI İNAkTİF EDER. overfiti önler.  daha az feature ile daha çok öğrenme yaılmasına bakar\n","\n","    # Tum veriyi Train ve Test olarak boluyoruz\n","    # X : data, Y label ları temsil eder. \n","    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)  # %20 test verisi. %80 train ayırır.\n","\n","    # Training\n","    classifier = SupervisedDBNClassification(hidden_layers_structure=hidden_layers_structure,\n","                                             learning_rate_rbm=learning_rate_rbm,\n","                                             learning_rate=learning_rate,\n","                                             n_epochs_rbm=n_epochs_rbm,\n","                                             n_iter_backprop=n_iter_backprop,\n","                                             batch_size=batch_size,\n","                                             activation_function=activation_function,\n","                                             dropout_p=dropout_p)\n","    classifier.fit(X_train, Y_train) #train datalarımızı fit ediyoz. ilk yapısı kurulur.\n","\n","    # Model Kaydet\n","    classifier.save('model.pkl')\n","\n","    # Modeli Geri getir\n","    classifier = SupervisedDBNClassification.load('model.pkl') # bu kod kalsın ama burada gerek yok. daha sonra çağırmak istediğinde bu kodu kullanarak çağır ve test et.\n","                                                                # gerek yok burda çünkü, zaten classifier ın içinde aynı model var. \n","\n","    # Test\n","    Y_pred = classifier.predict(X_test)  # test edilcek. verilen dataların çıkışlarına bakar, y_prede atar. \n","    acc = accuracy_score(Y_test, Y_pred)   # y_pred ile de acc bulursun.\n","    print('Done.\\nAccuracy: %f' % acc)\n","\n","    return acc   # bu fonk sonunda da bize acc verir."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BzZFXWPncJQL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623001462004,"user_tz":-180,"elapsed":27910,"user":{"displayName":"GÜLÇİN İNAT","photoUrl":"","userId":"13817032197419416640"}},"outputId":"34b7513f-7b99-4f9b-bf4f-087434e20cfa"},"source":["# Run DBN\n","default_acc = deep_belief_net()\n","print('ACCURACY: ' + str(default_acc))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[START] Pre-training step:\n","WARNING:tensorflow:From /content/gdrive/My Drive/Derin Öğrenme Final/DBN/dbn/tensorflow/models.py:153: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n",">> Epoch 1 finished \tRBM Reconstruction error 50.744282\n",">> Epoch 2 finished \tRBM Reconstruction error 60.294991\n",">> Epoch 3 finished \tRBM Reconstruction error 46.513248\n",">> Epoch 4 finished \tRBM Reconstruction error 35.211823\n",">> Epoch 5 finished \tRBM Reconstruction error 38.159405\n",">> Epoch 6 finished \tRBM Reconstruction error 53.689964\n",">> Epoch 7 finished \tRBM Reconstruction error 46.143444\n",">> Epoch 8 finished \tRBM Reconstruction error 51.302490\n",">> Epoch 9 finished \tRBM Reconstruction error 35.753780\n",">> Epoch 10 finished \tRBM Reconstruction error 41.548283\n",">> Epoch 1 finished \tRBM Reconstruction error 199.839294\n",">> Epoch 2 finished \tRBM Reconstruction error 205.839798\n",">> Epoch 3 finished \tRBM Reconstruction error 317.364868\n",">> Epoch 4 finished \tRBM Reconstruction error 225.926392\n",">> Epoch 5 finished \tRBM Reconstruction error 330.089996\n",">> Epoch 6 finished \tRBM Reconstruction error 329.241028\n",">> Epoch 7 finished \tRBM Reconstruction error 212.562561\n",">> Epoch 8 finished \tRBM Reconstruction error 354.176910\n",">> Epoch 9 finished \tRBM Reconstruction error 219.359787\n",">> Epoch 10 finished \tRBM Reconstruction error 248.504333\n","[END] Pre-training step\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","[START] Fine tuning step:\n",">> Epoch 0 finished \tANN training loss 0.731786\n",">> Epoch 1 finished \tANN training loss 0.461083\n",">> Epoch 2 finished \tANN training loss 0.370514\n",">> Epoch 3 finished \tANN training loss 0.342651\n",">> Epoch 4 finished \tANN training loss 0.306806\n",">> Epoch 5 finished \tANN training loss 0.260414\n",">> Epoch 6 finished \tANN training loss 0.202349\n",">> Epoch 7 finished \tANN training loss 0.191324\n",">> Epoch 8 finished \tANN training loss 0.176943\n",">> Epoch 9 finished \tANN training loss 0.158031\n",">> Epoch 10 finished \tANN training loss 0.138311\n",">> Epoch 11 finished \tANN training loss 0.116617\n",">> Epoch 12 finished \tANN training loss 0.109776\n",">> Epoch 13 finished \tANN training loss 0.109189\n",">> Epoch 14 finished \tANN training loss 0.093305\n",">> Epoch 15 finished \tANN training loss 0.077651\n",">> Epoch 16 finished \tANN training loss 0.077207\n",">> Epoch 17 finished \tANN training loss 0.064763\n",">> Epoch 18 finished \tANN training loss 0.057085\n",">> Epoch 19 finished \tANN training loss 0.061994\n",">> Epoch 20 finished \tANN training loss 0.050194\n",">> Epoch 21 finished \tANN training loss 0.046413\n",">> Epoch 22 finished \tANN training loss 0.063256\n",">> Epoch 23 finished \tANN training loss 0.039231\n",">> Epoch 24 finished \tANN training loss 0.035907\n",">> Epoch 25 finished \tANN training loss 0.030735\n",">> Epoch 26 finished \tANN training loss 0.026424\n",">> Epoch 27 finished \tANN training loss 0.025623\n",">> Epoch 28 finished \tANN training loss 0.023548\n",">> Epoch 29 finished \tANN training loss 0.022644\n",">> Epoch 30 finished \tANN training loss 0.022263\n",">> Epoch 31 finished \tANN training loss 0.020462\n",">> Epoch 32 finished \tANN training loss 0.019874\n",">> Epoch 33 finished \tANN training loss 0.018760\n",">> Epoch 34 finished \tANN training loss 0.016243\n",">> Epoch 35 finished \tANN training loss 0.015043\n",">> Epoch 36 finished \tANN training loss 0.016866\n",">> Epoch 37 finished \tANN training loss 0.012023\n",">> Epoch 38 finished \tANN training loss 0.011948\n",">> Epoch 39 finished \tANN training loss 0.011845\n",">> Epoch 40 finished \tANN training loss 0.010711\n",">> Epoch 41 finished \tANN training loss 0.011014\n",">> Epoch 42 finished \tANN training loss 0.010409\n",">> Epoch 43 finished \tANN training loss 0.008896\n",">> Epoch 44 finished \tANN training loss 0.007991\n",">> Epoch 45 finished \tANN training loss 0.008661\n",">> Epoch 46 finished \tANN training loss 0.007211\n",">> Epoch 47 finished \tANN training loss 0.006762\n",">> Epoch 48 finished \tANN training loss 0.008052\n",">> Epoch 49 finished \tANN training loss 0.006903\n",">> Epoch 50 finished \tANN training loss 0.006503\n",">> Epoch 51 finished \tANN training loss 0.005655\n",">> Epoch 52 finished \tANN training loss 0.005091\n",">> Epoch 53 finished \tANN training loss 0.005964\n",">> Epoch 54 finished \tANN training loss 0.006047\n",">> Epoch 55 finished \tANN training loss 0.004585\n",">> Epoch 56 finished \tANN training loss 0.004821\n",">> Epoch 57 finished \tANN training loss 0.004340\n",">> Epoch 58 finished \tANN training loss 0.003411\n",">> Epoch 59 finished \tANN training loss 0.003951\n",">> Epoch 60 finished \tANN training loss 0.004218\n",">> Epoch 61 finished \tANN training loss 0.003562\n",">> Epoch 62 finished \tANN training loss 0.003472\n",">> Epoch 63 finished \tANN training loss 0.003055\n",">> Epoch 64 finished \tANN training loss 0.002823\n",">> Epoch 65 finished \tANN training loss 0.002823\n",">> Epoch 66 finished \tANN training loss 0.002981\n",">> Epoch 67 finished \tANN training loss 0.002727\n",">> Epoch 68 finished \tANN training loss 0.004507\n",">> Epoch 69 finished \tANN training loss 0.002467\n",">> Epoch 70 finished \tANN training loss 0.002171\n",">> Epoch 71 finished \tANN training loss 0.002879\n",">> Epoch 72 finished \tANN training loss 0.002517\n",">> Epoch 73 finished \tANN training loss 0.003335\n",">> Epoch 74 finished \tANN training loss 0.002598\n",">> Epoch 75 finished \tANN training loss 0.001938\n",">> Epoch 76 finished \tANN training loss 0.001784\n",">> Epoch 77 finished \tANN training loss 0.002097\n",">> Epoch 78 finished \tANN training loss 0.001589\n",">> Epoch 79 finished \tANN training loss 0.001641\n",">> Epoch 80 finished \tANN training loss 0.001720\n",">> Epoch 81 finished \tANN training loss 0.001646\n",">> Epoch 82 finished \tANN training loss 0.001620\n",">> Epoch 83 finished \tANN training loss 0.001504\n",">> Epoch 84 finished \tANN training loss 0.001490\n",">> Epoch 85 finished \tANN training loss 0.001481\n",">> Epoch 86 finished \tANN training loss 0.001429\n",">> Epoch 87 finished \tANN training loss 0.001945\n",">> Epoch 88 finished \tANN training loss 0.001496\n",">> Epoch 89 finished \tANN training loss 0.001731\n",">> Epoch 90 finished \tANN training loss 0.001449\n",">> Epoch 91 finished \tANN training loss 0.001341\n",">> Epoch 92 finished \tANN training loss 0.001299\n",">> Epoch 93 finished \tANN training loss 0.001237\n",">> Epoch 94 finished \tANN training loss 0.001264\n",">> Epoch 95 finished \tANN training loss 0.001076\n",">> Epoch 96 finished \tANN training loss 0.001286\n",">> Epoch 97 finished \tANN training loss 0.001119\n",">> Epoch 98 finished \tANN training loss 0.001219\n",">> Epoch 99 finished \tANN training loss 0.001311\n","[END] Fine tuning step\n","Done.\n","Accuracy: 0.915000\n","ACCURACY: 0.915\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w4SfpHaYcJSj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623001485512,"user_tz":-180,"elapsed":19296,"user":{"displayName":"GÜLÇİN İNAT","photoUrl":"","userId":"13817032197419416640"}},"outputId":"2fa5e8bd-0fd1-448a-af29-58c6a1069117"},"source":["#Resetleyelim Accuracy - BİR ÖNCEKİ MODELDEN BİR PARAMTRE GELMESİN KARIŞMASIN DİYE\n","onelayer_acc = [0, 0, 0, 0, 0]\n","\n","#One layer structure\n","onelayer_acc[0] = deep_belief_net(hidden_layers_structure=[100])  # eğer bunu yazarsan bu paramatreyi vererek, diğer tüm değerleri default olarak aynı alır.\n","                                                                  # sadece bu girdiğin paramatereyi senin istediğini alır. \n","print('ACCURACY: ' + str(onelayer_acc[0]))\n","\n","\n","\n","\n","# NOT:\n","#ÇIKAN SONUÇTA ACC DEĞERİ TEST ACCSİDİR. \n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[START] Pre-training step:\n",">> Epoch 1 finished \tRBM Reconstruction error 61.622757\n",">> Epoch 2 finished \tRBM Reconstruction error 54.559200\n",">> Epoch 3 finished \tRBM Reconstruction error 77.086731\n",">> Epoch 4 finished \tRBM Reconstruction error 59.870129\n",">> Epoch 5 finished \tRBM Reconstruction error 52.185646\n",">> Epoch 6 finished \tRBM Reconstruction error 68.253036\n",">> Epoch 7 finished \tRBM Reconstruction error 73.334595\n",">> Epoch 8 finished \tRBM Reconstruction error 59.936142\n",">> Epoch 9 finished \tRBM Reconstruction error 81.631668\n",">> Epoch 10 finished \tRBM Reconstruction error 64.977356\n","[END] Pre-training step\n","[START] Fine tuning step:\n",">> Epoch 0 finished \tANN training loss 0.817047\n",">> Epoch 1 finished \tANN training loss 0.585387\n",">> Epoch 2 finished \tANN training loss 0.498027\n",">> Epoch 3 finished \tANN training loss 0.440307\n",">> Epoch 4 finished \tANN training loss 0.396710\n",">> Epoch 5 finished \tANN training loss 0.357965\n",">> Epoch 6 finished \tANN training loss 0.321930\n",">> Epoch 7 finished \tANN training loss 0.315167\n",">> Epoch 8 finished \tANN training loss 0.277858\n",">> Epoch 9 finished \tANN training loss 0.263177\n",">> Epoch 10 finished \tANN training loss 0.240098\n",">> Epoch 11 finished \tANN training loss 0.224673\n",">> Epoch 12 finished \tANN training loss 0.204717\n",">> Epoch 13 finished \tANN training loss 0.199875\n",">> Epoch 14 finished \tANN training loss 0.182319\n",">> Epoch 15 finished \tANN training loss 0.174085\n",">> Epoch 16 finished \tANN training loss 0.154938\n",">> Epoch 17 finished \tANN training loss 0.146663\n",">> Epoch 18 finished \tANN training loss 0.133237\n",">> Epoch 19 finished \tANN training loss 0.126113\n",">> Epoch 20 finished \tANN training loss 0.117124\n",">> Epoch 21 finished \tANN training loss 0.110157\n",">> Epoch 22 finished \tANN training loss 0.104790\n",">> Epoch 23 finished \tANN training loss 0.097339\n",">> Epoch 24 finished \tANN training loss 0.090554\n",">> Epoch 25 finished \tANN training loss 0.085803\n",">> Epoch 26 finished \tANN training loss 0.080748\n",">> Epoch 27 finished \tANN training loss 0.075451\n",">> Epoch 28 finished \tANN training loss 0.069971\n",">> Epoch 29 finished \tANN training loss 0.069172\n",">> Epoch 30 finished \tANN training loss 0.064289\n",">> Epoch 31 finished \tANN training loss 0.059002\n",">> Epoch 32 finished \tANN training loss 0.054529\n",">> Epoch 33 finished \tANN training loss 0.050348\n",">> Epoch 34 finished \tANN training loss 0.048899\n",">> Epoch 35 finished \tANN training loss 0.047428\n",">> Epoch 36 finished \tANN training loss 0.044785\n",">> Epoch 37 finished \tANN training loss 0.043395\n",">> Epoch 38 finished \tANN training loss 0.039610\n",">> Epoch 39 finished \tANN training loss 0.039190\n",">> Epoch 40 finished \tANN training loss 0.036301\n",">> Epoch 41 finished \tANN training loss 0.034874\n",">> Epoch 42 finished \tANN training loss 0.035259\n",">> Epoch 43 finished \tANN training loss 0.033147\n",">> Epoch 44 finished \tANN training loss 0.030236\n",">> Epoch 45 finished \tANN training loss 0.030900\n",">> Epoch 46 finished \tANN training loss 0.027193\n",">> Epoch 47 finished \tANN training loss 0.025179\n",">> Epoch 48 finished \tANN training loss 0.024808\n",">> Epoch 49 finished \tANN training loss 0.023048\n",">> Epoch 50 finished \tANN training loss 0.022202\n",">> Epoch 51 finished \tANN training loss 0.021140\n",">> Epoch 52 finished \tANN training loss 0.021269\n",">> Epoch 53 finished \tANN training loss 0.019510\n",">> Epoch 54 finished \tANN training loss 0.018731\n",">> Epoch 55 finished \tANN training loss 0.018705\n",">> Epoch 56 finished \tANN training loss 0.017746\n",">> Epoch 57 finished \tANN training loss 0.017170\n",">> Epoch 58 finished \tANN training loss 0.015900\n",">> Epoch 59 finished \tANN training loss 0.015817\n",">> Epoch 60 finished \tANN training loss 0.015212\n",">> Epoch 61 finished \tANN training loss 0.014258\n",">> Epoch 62 finished \tANN training loss 0.014344\n",">> Epoch 63 finished \tANN training loss 0.013961\n",">> Epoch 64 finished \tANN training loss 0.013390\n",">> Epoch 65 finished \tANN training loss 0.012538\n",">> Epoch 66 finished \tANN training loss 0.011785\n",">> Epoch 67 finished \tANN training loss 0.012152\n",">> Epoch 68 finished \tANN training loss 0.011481\n",">> Epoch 69 finished \tANN training loss 0.011499\n",">> Epoch 70 finished \tANN training loss 0.011011\n",">> Epoch 71 finished \tANN training loss 0.011254\n",">> Epoch 72 finished \tANN training loss 0.010962\n",">> Epoch 73 finished \tANN training loss 0.009958\n",">> Epoch 74 finished \tANN training loss 0.009796\n",">> Epoch 75 finished \tANN training loss 0.009698\n",">> Epoch 76 finished \tANN training loss 0.009133\n",">> Epoch 77 finished \tANN training loss 0.008899\n",">> Epoch 78 finished \tANN training loss 0.009074\n",">> Epoch 79 finished \tANN training loss 0.009170\n",">> Epoch 80 finished \tANN training loss 0.009337\n",">> Epoch 81 finished \tANN training loss 0.009029\n",">> Epoch 82 finished \tANN training loss 0.008080\n",">> Epoch 83 finished \tANN training loss 0.008363\n",">> Epoch 84 finished \tANN training loss 0.007259\n",">> Epoch 85 finished \tANN training loss 0.007006\n",">> Epoch 86 finished \tANN training loss 0.006848\n",">> Epoch 87 finished \tANN training loss 0.006797\n",">> Epoch 88 finished \tANN training loss 0.006739\n",">> Epoch 89 finished \tANN training loss 0.006797\n",">> Epoch 90 finished \tANN training loss 0.006921\n",">> Epoch 91 finished \tANN training loss 0.006349\n",">> Epoch 92 finished \tANN training loss 0.006338\n",">> Epoch 93 finished \tANN training loss 0.006233\n",">> Epoch 94 finished \tANN training loss 0.005977\n",">> Epoch 95 finished \tANN training loss 0.005815\n",">> Epoch 96 finished \tANN training loss 0.005777\n",">> Epoch 97 finished \tANN training loss 0.005816\n",">> Epoch 98 finished \tANN training loss 0.005553\n",">> Epoch 99 finished \tANN training loss 0.005441\n","[END] Fine tuning step\n","Done.\n","Accuracy: 0.925000\n","ACCURACY: 0.925\n"],"name":"stdout"}]}]}